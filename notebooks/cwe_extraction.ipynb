{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from the CWE List\n",
    "MITRE's CWE list contains lots of information that could be pertinant to our analysis that's relatively easy to access. Among these I counted the CWE IDs, names, descriptions, related CWEs, the nature of these relationships, the technological vector (web-based, network, etc.), background details, the phases of development wherein the weakness could be introduced, descriptions about these unfortunate events, the likelihood of these weaknesses, the scope and impact of the weakness's common consequences, detection methods and their descriptions and effectiveness, mitigation strategies, potential vulnerabilities, observed vulnerabilities (with direct references to CVE IDs), and more. Because there's so much text data in the CWE list, we should have plenty of information to feed into a matural language processing pipeline that can help build a classification model to predict the association of a given CVE with the IoT device and it's various vulnerabilities should our research gravitate in that direction. <span style='color:#00aa00;font-weight:bold;'>Regardless, we may find useful information in our quest to produce a scoring system that improves patch readiness</span>.\n",
    "\n",
    "I created several helper functions to get us from `A` to `B`. The first, I can just feed the XML file. Next, we have a function that takes an element and takes all of the text data inside of it and it's children nodes and returns it as a long sentence. This kind of column data will be useful when we tokenize and lemmatize the text to more accurately search for our desire IoT-vulnerability-related keywords."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def readXML(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        return root\n",
    "    except ET.ParseError as e:\n",
    "        print(f'Error parsing {file_path}: {e}')\n",
    "        return None\n",
    "\n",
    "def extract_txt_from_el(element):\n",
    "    if element is None:\n",
    "        return ''\n",
    "    txt_parts = [element.text or '']\n",
    "    for child in element:\n",
    "        txt_parts.append(extract_txt_from_el(child))\n",
    "        if child.tail:\n",
    "            txt_parts.append(child.tail)\n",
    "    return ' '.join(filter(None, txt_parts)).strip()\n",
    "\n",
    "def extract_data(root):\n",
    "    data = []\n",
    "    ns = {\n",
    "        'ns': 'http://cwe.mitre.org/cwe-7',\n",
    "        'xhtml': 'http://www.w3.org/1999/xhtml',\n",
    "        'xsi': 'http://www.w3.org/2001/XMLSchema-instance'\n",
    "    }\n",
    "    weaknesses = root.findall('.//ns:Weakness', ns)\n",
    "\n",
    "    # Debugging\n",
    "    if not weaknesses:\n",
    "        print('No Weaknesses found')\n",
    "        return data\n",
    "\n",
    "    for weakness in weaknesses:\n",
    "        # Basic info\n",
    "        cwe_id = weakness.get('ID')\n",
    "        name = weakness.get('Name')\n",
    "        desc = extract_txt_from_el(weakness.find('ns:Description', ns))\n",
    "        ext_desc = extract_txt_from_el(weakness.find('ns:Extended_Description', ns))\n",
    "        description = f'{desc} {ext_desc}'.strip()\n",
    "\n",
    "        # Related weakness info\n",
    "        rel_ids, nature_of_rels = [], []\n",
    "        related_weaknesses = weakness.find('ns:Related_Weaknesses', ns)\n",
    "        if related_weaknesses is not None:\n",
    "            for rel_weakness in related_weaknesses.findall('ns:Related_Weakness', ns):\n",
    "                rel_id = rel_weakness.get('CWE_ID')\n",
    "                nature = rel_weakness.get('Nature')\n",
    "                rel_ids.append(rel_id)\n",
    "                nature_of_rels.append(nature)\n",
    "\n",
    "        # Technical info\n",
    "        tech_el = weakness.find('.//ns:Technology', ns)\n",
    "        tech_class = tech_el.get('Class') if tech_el is not None else ''\n",
    "        bg_details = extract_txt_from_el(weakness.find('ns:Background_Details/ns:Background_Detail', ns))\n",
    "\n",
    "        # Modes of introduction\n",
    "        modes_of_intro_phases, modes_of_intro_descs = [], []\n",
    "        modes_of_intro = weakness.find('ns:Modes_Of_Introduction', ns)\n",
    "        if modes_of_intro is not None:\n",
    "            for mode in modes_of_intro:\n",
    "                modes_of_intro_phase = mode.find('ns:Phase', ns).text if mode.find('ns:Phase', ns) is not None else ''\n",
    "                modes_of_intro_note = mode.find('ns:Note', ns).text if mode.find('ns:Note', ns) is not None else ''\n",
    "                # Append data to the columns\n",
    "                modes_of_intro_phases.append(modes_of_intro_phase)\n",
    "                modes_of_intro_descs.append(modes_of_intro_note)\n",
    "\n",
    "        # Likelihood of exploitation\n",
    "        likelihood = extract_txt_from_el(weakness.find('ns:Likelihood_Of_Exploit', ns))\n",
    "\n",
    "        # Consequence info\n",
    "        scope_of_consequences, impact_of_consequences, consequence_notes = [], [], []\n",
    "        consequences = weakness.find('ns:Common_Consequences', ns)\n",
    "        if consequences is not None:\n",
    "            for consequence in consequences:\n",
    "                scope = consequence.find('ns:Scope', ns).text if consequence.find('ns:Scope', ns) is not None else ''\n",
    "                impact = consequence.find('ns:Impact', ns).text if consequence.find('ns:Impact', ns) is not None else ''\n",
    "                note = consequence.find('ns:Note', ns).text if consequence.find('ns:Note', ns) is not None else ''\n",
    "                scope_of_consequences.append(scope)\n",
    "                impact_of_consequences.append(impact)\n",
    "                consequence_notes.append(note)\n",
    "\n",
    "        # Detection info\n",
    "        detect_methods = []\n",
    "        detect_descs = []\n",
    "        detect_effectiveness = []\n",
    "        detection_methods = weakness.find('ns:Detection_Methods', ns)\n",
    "        if detection_methods is not None:\n",
    "            for method in detection_methods:\n",
    "                detect_method = method.find('ns:Method', ns).text if method.find('ns:Method', ns) is not None else ''\n",
    "                detect_desc = method.find('ns:Description', ns).text if method.find('ns:Description', ns) is not None else ''\n",
    "                detect_effect = method.find('ns:Effectiveness', ns).text if method.find('ns:Effectiveness', ns) is not None else ''\n",
    "                # Append data to the columns\n",
    "                detect_methods.append(detect_method)\n",
    "                detect_descs.append(detect_desc)\n",
    "                detect_effectiveness.append(detect_effect)\n",
    "\n",
    "        # Mitigation info\n",
    "        mitigate_phases = []\n",
    "        mitigate_descs = []\n",
    "        mitigate_effectivenesses = []\n",
    "        mitigate_notes = []\n",
    "        potential_mitigations = weakness.find('ns:Potential_Mitigations', ns)\n",
    "        if potential_mitigations is not None:\n",
    "            for mitigation in potential_mitigations:\n",
    "                mitigate_phase = mitigation.find('.//ns:Phase', ns)\n",
    "                mitigate_phase = mitigate_phase.text if mitigate_phase is not None else ''\n",
    "\n",
    "                # Build a mitigation description\n",
    "                mitigate_desc_el = mitigation.find('ns:Description', ns)\n",
    "                if mitigate_desc_el is not None:\n",
    "                    desc_parts = []\n",
    "                    if mitigate_desc_el.text:\n",
    "                        desc_parts.append(mitigate_desc_el.text.strip())\n",
    "                    for part in mitigate_desc_el.findall('.//xhtml:p', ns):\n",
    "                        if part.text:\n",
    "                            desc_parts.append(part.text.strip())\n",
    "                    mitigate_descs.append(' '.join(desc_parts))\n",
    "                else:\n",
    "                    mitigate_descs.append('')\n",
    "\n",
    "                mitigate_effectiveness = mitigation.find('ns:Effectiveness', ns)\n",
    "                mitigate_effectiveness = mitigate_effectiveness.text if mitigate_effectiveness is not None else ''\n",
    "\n",
    "                mitigate_note = mitigation.find('ns:Effectiveness_Notes', ns)\n",
    "                mitigate_note = mitigate_note.text if mitigate_note is not None else ''\n",
    "                # Append data to the columns\n",
    "                mitigate_phases.append(mitigate_phase)\n",
    "                mitigate_effectivenesses.append(mitigate_effectiveness)\n",
    "                mitigate_notes.append(mitigate_note)\n",
    "\n",
    "\n",
    "        observed_vulnerabilities = []\n",
    "        vulnerability_descs = []\n",
    "        observed_examples = weakness.find('ns:Observed_Examples', ns)\n",
    "        if observed_examples is not None:\n",
    "            for cve in observed_examples.findall('ns:Observed_Example', ns):\n",
    "                observed_vulnerability = cve.find('ns:Reference', ns).text if cve.find('ns:Reference', ns) is not None else ''\n",
    "                vulnerability_desc = cve.find('ns:Description', ns).text if cve.find('ns:Description', ns) is not None else ''\n",
    "                # Append data to the columns\n",
    "                observed_vulnerabilities.append(observed_vulnerability)\n",
    "                vulnerability_descs.append(vulnerability_desc)\n",
    "\n",
    "        data.append({\n",
    "            'cwe_id': cwe_id,\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'tech_class': tech_class,\n",
    "            'bg_details': bg_details,\n",
    "            'rel_ids': rel_ids,\n",
    "            'nature_of_rels': nature_of_rels,\n",
    "            'modes_of_intro_phases': modes_of_intro_phases,\n",
    "            'modes_of_intro_descs': modes_of_intro_descs,\n",
    "            'likelihood': likelihood,\n",
    "            'scope_of_consequences': scope_of_consequences,\n",
    "            'impact_of_consequences': impact_of_consequences,\n",
    "            'consequence_notes': consequence_notes,\n",
    "            'detection_method': detect_methods,\n",
    "            'detection_desc': detect_descs,\n",
    "            'detection_effectiveness': detect_effectiveness,\n",
    "            'mitigation_phases': mitigate_phase,\n",
    "            'mitigation_descs': mitigate_descs,\n",
    "            'mitigation_effectiveness': mitigate_effectivenesses,\n",
    "            'mitigate_notes': mitigate_notes,\n",
    "            'observed_vulnerabilities': observed_vulnerabilities,\n",
    "            'vulnerability_descs': vulnerability_descs\n",
    "        })\n",
    "    return data\n",
    "\n",
    "file = '../data/CWE_V4.15/CWE_v4.15.xml'\n",
    "root = readXML(file)\n",
    "data = extract_data(root)\n",
    "\n",
    "# Construct the dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Saving the Data\n",
    "Parquet is a file type that streamlines the storage and retrieval of columnar data since it is capable of saving the type of data within the set. Even though CSV files do not have this capability, they are easily shared and viewable in common spreadsheet software. Because of this, I saved a copy with both file extensions. I chose to use the default option `None` for the method's `index` parameter, which saves the index of each record in a special kind of metadata range loop. This means it won't take up the kind of memory it would have if the index was actually saved into the dataframe as a separate attribute, but also provides a way to keep track of the records for the purposes of splitting them up between training, test, and validation sets for an machine-learning algorithm should our work come to that.\n",
    "\n",
    "<span style='font-weight:600;color:#ff9900;background-color:#525767;border-radius:3px;padding-inline:3px;padding-block:1px;'>Don't run this code cells unless you want to overwrite the saved files!</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Saving CWE list\n",
    "df.to_parquet(path='../data/CWE_List.parquet', index=None)\n",
    "df.to_csv('../data/CVE_V5/CWE_List.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
