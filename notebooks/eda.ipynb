{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Notebook\n",
    "This notebook is dedicated to the exploratory data analysis of the large and focused final data sets. General facts about the data will be recorded and available in the following cells. Should it be warranted, they may also appear in the README file. We'll be using Pandas and Numpy for data processing and analysis and `matplotlib` and `seaborn` for data visualization. The first step is to load in the libraries and the data we're interested in. This data has already been cleaned up, but it still contains null values in some attributes that will have to handled during certain operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sb\n",
    "import textwrap as txt\n",
    "\n",
    "df = pd.read_parquet(path='../data/processed/composite/dataset_focused.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to look at are general facts about the data we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6259 entries, 0 to 6258\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   cve_id             6259 non-null   string             \n",
      " 1   exploit_count      6259 non-null   Int64              \n",
      " 2   exploitation_date  5506 non-null   datetime64[ns, UTC]\n",
      " 3   cvss               1565 non-null   Float64            \n",
      " 4   cvss_severity      1565 non-null   category           \n",
      " 5   date_published     5924 non-null   datetime64[ns, UTC]\n",
      " 6   epss               2253 non-null   Float64            \n",
      " 7   percentile         2253 non-null   Float64            \n",
      "dtypes: Float64(3), Int64(1), category(1), datetime64[ns, UTC](2), string(1)\n",
      "memory usage: 373.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are \u001b[32;1m6259\u001b[0m CVE records in the data frame, each with \u001b[32;1m8\u001b[0m attributes.\n",
      "Some general statistics about the numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exploit_count</th>\n",
       "      <td>6259.0</td>\n",
       "      <td>2.292858</td>\n",
       "      <td>7.765336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cvss</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>7.767987</td>\n",
       "      <td>1.734501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epss</th>\n",
       "      <td>2253.0</td>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.150789</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.00358</td>\n",
       "      <td>0.01404</td>\n",
       "      <td>0.97516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile</th>\n",
       "      <td>2253.0</td>\n",
       "      <td>0.459049</td>\n",
       "      <td>0.308128</td>\n",
       "      <td>0.043279</td>\n",
       "      <td>0.16754</td>\n",
       "      <td>0.39478</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.99991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std       min      25%      50%  \\\n",
       "exploit_count  6259.0  2.292858  7.765336       1.0      1.0      1.0   \n",
       "cvss           1565.0  7.767987  1.734501       0.0      6.6      7.8   \n",
       "epss           2253.0  0.047891  0.150789   0.00042  0.00048  0.00358   \n",
       "percentile     2253.0  0.459049  0.308128  0.043279  0.16754  0.39478   \n",
       "\n",
       "                   75%      max  \n",
       "exploit_count      1.0    391.0  \n",
       "cvss               9.1     10.0  \n",
       "epss           0.01404  0.97516  \n",
       "percentile     0.74964  0.99991  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are \\033[32;1m{df.shape[0]}\\033[0m CVE records in the data frame, each with \\033[32;1m{df.shape[1]}\\033[0m attributes.')\n",
    "print('Some general statistics about the numerical columns:')\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    There are \u001b[32;1m1131\u001b[0m CVEs with a CVSS score greater than or equal\n",
      "to 7.0, \u001b[32;1m72.27%\u001b[0m of the total number of CVSS scores contained in\n",
      "the dataset. Of these CVEs, \u001b[32;1m694\u001b[0m have valid EPSS scores.\n",
      "\u001b[32;1m15\u001b[0m of the CVEs have EPSS scores that fall above a threshold of\n",
      "0.5, meaning those with a 50% chance of being exploited in the 30 days\n",
      "after said scores were calculated. This is \u001b[32;1m2.16%\u001b[0m of our valid\n",
      "EPSS scores, and \u001b[32;1m0.67%\u001b[0m of the total number of EPSS scores\n",
      "contained in the dataset. This suggests that most CVEs, even those with\n",
      "severe CVSS scores, are not likely to be exploited in the 30 days after.\n"
     ]
    }
   ],
   "source": [
    "cvss_greater_than_or_equal_to_7 = df[df['cvss'] >= 7.0]\n",
    "cvss_greater_than_or_equal_to_7_count = len(cvss_greater_than_or_equal_to_7)\n",
    "nonnull_epss = cvss_greater_than_or_equal_to_7[cvss_greater_than_or_equal_to_7['epss'].notnull()]\n",
    "valid_epss_threshold = nonnull_epss[nonnull_epss['epss'] >= 0.5]\n",
    "\n",
    "output = txt.fill(\n",
    "    f\"There are \\033[32;1m{cvss_greater_than_or_equal_to_7_count}\\033[0m CVEs with a CVSS score greater than or equal to 7.0, \\033[32;1m{(cvss_greater_than_or_equal_to_7_count / df['cvss'].count()) * 100:.2f}%\\033[0m of the total number of CVSS scores contained in the dataset. Of these CVEs, \\033[32;1m{len(nonnull_epss)}\\033[0m have valid EPSS scores. \\033[32;1m{len(valid_epss_threshold)}\\033[0m of the CVEs have EPSS scores that fall above a threshold of 0.5, meaning those with a 50% chance of being exploited in the 30 days after said scores were calculated. This is \\033[32;1m{(len(valid_epss_threshold) / len(nonnull_epss)) * 100:.2f}%\\033[0m of our valid EPSS scores, and \\033[32;1m{(len(valid_epss_threshold) / df['epss'].count()) * 100:.2f}%\\033[0m of the total number of EPSS scores contained in the dataset. This suggests that most CVEs, even those with severe CVSS scores, are not likely to be exploited in the 30 days after.\",\n",
    "    initial_indent='    ',\n",
    "    width=75,\n",
    "    break_long_words=False,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Distributive Normalcy\n",
    "### Histogram Plots\n",
    "From the looks of the histogram plots, the CVSS scores seem normal (because of the bell curve) but the days to patch and days to exploit don't seem normal; rather, they seem heavily skewed to the right and even bimodal, respectively. We can't rely on appearances alone though, so in the next section, we'll use several statistical tests to verify the data's shape mathematically. The histogram plots are superimposed with a kernel density estimation (KDE) that approximates the shape of the distribution. Taken together, we can see that the test data, though theoretically continuous, has larger gaps where certain potential values are not represented. This makes interpreting the results of the normality testing that follows less accurate since they all expect continuous data. This issue may sufficiently fall away when testing our actual dataset given its larger sample size. Fortunately for now, non-parametric tests like Spearman's correlation and Kendall's Tau can handle discrete variables, but we'll still go through normality testing to verify the discreteness of our current test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to test\n",
    "cvss = df['cvss']\n",
    "epss = df['epss']\n",
    "days_to_exploit = df['days_to_exploit']\n",
    "dtfe = df['days_to_first_exploit']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
