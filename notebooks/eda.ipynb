{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Notebook\n",
    "This notebook is dedicated to the exploratory data analysis of the large and focused final data sets. General facts about the data will be recorded and available in the following cells. Should it be warranted, they may also appear in the README file. We'll be using Pandas and Numpy for data processing and analysis and `matplotlib` and `seaborn` for data visualization. The first step is to load in the libraries and the data we're interested in. This data has already been cleaned up, but it still contains null values in some attributes that will have to handled during certain operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import scipy.stats as stats\n",
    "# import matplotlib.pyplot as plot\n",
    "# import seaborn as sbn\n",
    "import textwrap as txt\n",
    "\n",
    "# Import utility functions\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from classes import Plotter\n",
    "\n",
    "df = pd.read_parquet(path='../data/processed/composite/dataset_focused.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to look at are general facts about the data we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10891 entries, 0 to 10890\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype              \n",
      "---  ------                --------------  -----              \n",
      " 0   cve_id                10891 non-null  string             \n",
      " 1   date_public           10678 non-null  datetime64[ns, UTC]\n",
      " 2   origin                10891 non-null  category           \n",
      " 3   cvss                  10290 non-null  Float64            \n",
      " 4   cvss_severity         10891 non-null  category           \n",
      " 5   cvss_src              10290 non-null  category           \n",
      " 6   exploit_count         10891 non-null  Float64            \n",
      " 7   days_to_poc_exploit   10678 non-null  Float64            \n",
      " 8   exploitation_date_0   10891 non-null  datetime64[ns, UTC]\n",
      " 9   epss_0                3969 non-null   Float64            \n",
      " 10  percentile_0          2886 non-null   Float64            \n",
      " 11  exploitation_date_30  4654 non-null   datetime64[ns, UTC]\n",
      " 12  epss_30               4003 non-null   Float64            \n",
      " 13  percentile_30         3965 non-null   Float64            \n",
      " 14  exploitation_date_60  4654 non-null   datetime64[ns, UTC]\n",
      " 15  epss_60               4116 non-null   Float64            \n",
      " 16  percentile_60         4008 non-null   Float64            \n",
      " 17  change_0_to_30        3945 non-null   Float64            \n",
      " 18  change_30_to_60       3945 non-null   Float64            \n",
      " 19  change_0_60           3945 non-null   Float64            \n",
      "dtypes: Float64(12), category(3), datetime64[ns, UTC](4), string(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are \u001b[32;1m10891\u001b[0m CVE records in the data frame, each with \u001b[32;1m20\u001b[0m attributes.\n",
      "Some general statistics about the numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cvss</th>\n",
       "      <td>10290.0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1.794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploit_count</th>\n",
       "      <td>10891.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_to_poc_exploit</th>\n",
       "      <td>10678.0</td>\n",
       "      <td>230.404</td>\n",
       "      <td>790.141</td>\n",
       "      <td>-4457.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epss_0</th>\n",
       "      <td>3969.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile_0</th>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epss_30</th>\n",
       "      <td>4003.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile_30</th>\n",
       "      <td>3965.0</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epss_60</th>\n",
       "      <td>4116.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile_60</th>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_0_to_30</th>\n",
       "      <td>3945.0</td>\n",
       "      <td>1910.202</td>\n",
       "      <td>15133.251</td>\n",
       "      <td>-32500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>226241.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_30_to_60</th>\n",
       "      <td>3945.0</td>\n",
       "      <td>236.072</td>\n",
       "      <td>5522.94</td>\n",
       "      <td>-1823.913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224772.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_0_60</th>\n",
       "      <td>3945.0</td>\n",
       "      <td>2375.231</td>\n",
       "      <td>18322.683</td>\n",
       "      <td>-65000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.924</td>\n",
       "      <td>450455.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count      mean        std       min    25%    50%  \\\n",
       "cvss                 10290.0      7.36      1.794       0.0    6.1    7.5   \n",
       "exploit_count        10891.0      1.86      5.999       1.0    1.0    1.0   \n",
       "days_to_poc_exploit  10678.0   230.404    790.141   -4457.0    0.0    1.0   \n",
       "epss_0                3969.0     0.067      0.191    -0.783    0.0  0.004   \n",
       "percentile_0          2886.0     0.488      0.317     0.008  0.194   0.42   \n",
       "epss_30               4003.0       0.1      0.224       0.0  0.001  0.009   \n",
       "percentile_30         3965.0     0.554      0.334     0.008  0.229  0.563   \n",
       "epss_60               4116.0     0.104      0.236    -0.008  0.001  0.009   \n",
       "percentile_60         4008.0     0.557      0.334     0.008  0.243  0.565   \n",
       "change_0_to_30        3945.0  1910.202  15133.251  -32500.0    0.0    0.0   \n",
       "change_30_to_60       3945.0   236.072    5522.94 -1823.913    0.0    0.0   \n",
       "change_0_60           3945.0  2375.231  18322.683  -65000.0    0.0    0.0   \n",
       "\n",
       "                        75%         max  \n",
       "cvss                    8.8        10.0  \n",
       "exploit_count           1.0       394.0  \n",
       "days_to_poc_exploit    66.0      9978.0  \n",
       "epss_0                 0.02       1.019  \n",
       "percentile_0          0.788         1.0  \n",
       "epss_30               0.051       0.975  \n",
       "percentile_30         0.895         1.0  \n",
       "epss_60               0.052       1.937  \n",
       "percentile_60         0.898         1.0  \n",
       "change_0_to_30         20.0   226241.86  \n",
       "change_30_to_60         0.0  224772.093  \n",
       "change_0_60          29.924  450455.814  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are \\033[32;1m{df.shape[0]}\\033[0m CVE records in the data frame, each with \\033[32;1m{df.shape[1]}\\033[0m attributes.')\n",
    "print('Some general statistics about the numerical columns:')\n",
    "\n",
    "# Change output display for clarity\n",
    "pd.options.display.precision = 3\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $601$ CVEs with `UNKNOWN` CVSS score severities, calculated by virtue of their corresponding scores not belonging to the range of applicable numbers as set forth by FIRST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvss_severity\n",
       "UNKNOWN     601\n",
       "CRITICAL      0\n",
       "HIGH          0\n",
       "LOW           0\n",
       "MEDIUM        0\n",
       "NONE          0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['cvss'].isnull()) & (df['cvss_severity'].notnull())]['cvss_severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date_public</th>\n",
       "      <td>10678</td>\n",
       "      <td>2016-01-07 08:06:07.169118464+00:00</td>\n",
       "      <td>1990-08-14 04:00:00+00:00</td>\n",
       "      <td>2008-12-01 00:00:00+00:00</td>\n",
       "      <td>2018-04-19 12:00:00+00:00</td>\n",
       "      <td>2022-05-24 23:53:15+00:00</td>\n",
       "      <td>2025-01-28 22:15:15.860000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploitation_date_0</th>\n",
       "      <td>10891</td>\n",
       "      <td>2016-10-06 01:45:41.016527616+00:00</td>\n",
       "      <td>1990-05-19 00:00:00+00:00</td>\n",
       "      <td>2009-04-20 00:00:00+00:00</td>\n",
       "      <td>2019-10-15 06:26:08+00:00</td>\n",
       "      <td>2023-01-31 22:51:30+00:00</td>\n",
       "      <td>2025-01-13 10:07:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploitation_date_30</th>\n",
       "      <td>4654</td>\n",
       "      <td>2023-05-27 01:51:19.655350272+00:00</td>\n",
       "      <td>2021-05-14 00:00:00+00:00</td>\n",
       "      <td>2022-05-26 11:11:19+00:00</td>\n",
       "      <td>2023-07-05 17:10:29.500000+00:00</td>\n",
       "      <td>2024-05-03 17:20:47.750000128+00:00</td>\n",
       "      <td>2025-02-12 10:07:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploitation_date_60</th>\n",
       "      <td>4654</td>\n",
       "      <td>2023-06-26 01:51:19.655350272+00:00</td>\n",
       "      <td>2021-06-13 00:00:00+00:00</td>\n",
       "      <td>2022-06-25 11:11:19+00:00</td>\n",
       "      <td>2023-08-04 17:10:29.500000+00:00</td>\n",
       "      <td>2024-06-02 17:20:47.750000128+00:00</td>\n",
       "      <td>2025-03-14 10:07:25+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count                                 mean  \\\n",
       "date_public           10678  2016-01-07 08:06:07.169118464+00:00   \n",
       "exploitation_date_0   10891  2016-10-06 01:45:41.016527616+00:00   \n",
       "exploitation_date_30   4654  2023-05-27 01:51:19.655350272+00:00   \n",
       "exploitation_date_60   4654  2023-06-26 01:51:19.655350272+00:00   \n",
       "\n",
       "                                            min                        25%  \\\n",
       "date_public           1990-08-14 04:00:00+00:00  2008-12-01 00:00:00+00:00   \n",
       "exploitation_date_0   1990-05-19 00:00:00+00:00  2009-04-20 00:00:00+00:00   \n",
       "exploitation_date_30  2021-05-14 00:00:00+00:00  2022-05-26 11:11:19+00:00   \n",
       "exploitation_date_60  2021-06-13 00:00:00+00:00  2022-06-25 11:11:19+00:00   \n",
       "\n",
       "                                                   50%  \\\n",
       "date_public                  2018-04-19 12:00:00+00:00   \n",
       "exploitation_date_0          2019-10-15 06:26:08+00:00   \n",
       "exploitation_date_30  2023-07-05 17:10:29.500000+00:00   \n",
       "exploitation_date_60  2023-08-04 17:10:29.500000+00:00   \n",
       "\n",
       "                                                      75%  \\\n",
       "date_public                     2022-05-24 23:53:15+00:00   \n",
       "exploitation_date_0             2023-01-31 22:51:30+00:00   \n",
       "exploitation_date_30  2024-05-03 17:20:47.750000128+00:00   \n",
       "exploitation_date_60  2024-06-02 17:20:47.750000128+00:00   \n",
       "\n",
       "                                                   max  \n",
       "date_public           2025-01-28 22:15:15.860000+00:00  \n",
       "exploitation_date_0          2025-01-13 10:07:25+00:00  \n",
       "exploitation_date_30         2025-02-12 10:07:25+00:00  \n",
       "exploitation_date_60         2025-03-14 10:07:25+00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols = df.select_dtypes('datetime64[ns, UTC]').columns\n",
    "df[date_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         There are \u001b[32;1m6706\u001b[0m CVEs with a CVSS score greater than or\n",
      "equal to 7.0, \u001b[32;1m65.17%\u001b[0m of the total number     of CVSS scores\n",
      "contained in the dataset. Of these CVEs, \u001b[32;1m2826\u001b[0m have valid\n",
      "EPSS scores. \u001b[32;1m180\u001b[0m of the CVEs have EPSS scores that fall above a\n",
      "threshold     of 0.5, meaning those with a 50% chance of being exploited in\n",
      "the 30 days after said scores were calculated.     This is \u001b[32;1m6.37%\u001b[0m\n",
      "of our valid EPSS scores, and \u001b[32;1m4.54%\u001b[0m     of the total number of\n",
      "EPSS scores contained in the dataset. This suggests that most CVEs, even\n",
      "those with severe CVSS scores,     are not likely to be exploited in the 30\n",
      "days after.\n"
     ]
    }
   ],
   "source": [
    "cvss_greater_than_or_equal_to_7 = df[df['cvss'] >= 7.0]\n",
    "cvss_greater_than_or_equal_to_7_count = len(cvss_greater_than_or_equal_to_7)\n",
    "nonnull_epss = cvss_greater_than_or_equal_to_7[cvss_greater_than_or_equal_to_7['epss_0'].notnull()]\n",
    "valid_epss_threshold = nonnull_epss[nonnull_epss['epss_0'] >= 0.5]\n",
    "\n",
    "text = f\"\"\"\n",
    "    There are \\033[32;1m{cvss_greater_than_or_equal_to_7_count}\\033[0m CVEs with a CVSS score greater than or\n",
    "    equal to 7.0, \\033[32;1m{(cvss_greater_than_or_equal_to_7_count / df['cvss'].count()) * 100:.2f}%\\033[0m of the total number\n",
    "    of CVSS scores contained in the dataset. Of these CVEs, \\033[32;1m{len(nonnull_epss)}\\033[0m have valid\n",
    "    EPSS scores. \\033[32;1m{len(valid_epss_threshold)}\\033[0m of the CVEs have EPSS scores that fall above a threshold\n",
    "    of 0.5, meaning those with a 50% chance of being exploited in the 30 days after said scores were calculated.\n",
    "    This is \\033[32;1m{(len(valid_epss_threshold) / len(nonnull_epss)) * 100:.2f}%\\033[0m of our valid EPSS scores, and \\033[32;1m{(len(valid_epss_threshold) / df['epss_0'].count()) * 100:.2f}%\\033[0m\n",
    "    of the total number of EPSS scores contained in the dataset. This suggests that most CVEs, even those with severe CVSS scores,\n",
    "    are not likely to be exploited in the 30 days after.\n",
    "\"\"\"\n",
    "\n",
    "output = txt.fill(\n",
    "    text,\n",
    "    initial_indent='    ',\n",
    "    width=75,\n",
    "    break_long_words=False,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Distributive Normalcy\n",
    "### Histogram, Q-Q Plots, and Scatterplots\n",
    "From the looks of the histogram and Q-Q plots, none of the project's variables appear to be normally distributed; rather, they seem heavily skewed to the right, exponential, and perhaps bimodal. We can't rely on appearances alone though, so in the next section, we'll use several statistical tests to verify the data's shape mathematically.\n",
    "\n",
    "Based on the results of these tests, we can perform correlation analysis with the Spearman's Rank Coefficient and Kendall's Tau and begin to flesh out an analysis that will help validate the effectiveness of the project's model versus the CVSS and EPSS parameters. Scatterplots graphing the relationship between variables will help in this endeavour to visualize any relationships that may emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10891 entries, 0 to 10890\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype              \n",
      "---  ------                --------------  -----              \n",
      " 0   cve_id                10891 non-null  string             \n",
      " 1   date_public           10678 non-null  datetime64[ns, UTC]\n",
      " 2   origin                10891 non-null  category           \n",
      " 3   cvss                  10290 non-null  Float64            \n",
      " 4   cvss_severity         10891 non-null  category           \n",
      " 5   cvss_src              10290 non-null  category           \n",
      " 6   exploit_count         10891 non-null  Float64            \n",
      " 7   days_to_poc_exploit   10678 non-null  Float64            \n",
      " 8   exploitation_date_0   10891 non-null  datetime64[ns, UTC]\n",
      " 9   epss_0                3969 non-null   Float64            \n",
      " 10  percentile_0          2886 non-null   Float64            \n",
      " 11  exploitation_date_30  4654 non-null   datetime64[ns, UTC]\n",
      " 12  epss_30               4003 non-null   Float64            \n",
      " 13  percentile_30         3965 non-null   Float64            \n",
      " 14  exploitation_date_60  4654 non-null   datetime64[ns, UTC]\n",
      " 15  epss_60               4116 non-null   Float64            \n",
      " 16  percentile_60         4008 non-null   Float64            \n",
      " 17  change_0_to_30        3945 non-null   Float64            \n",
      " 18  change_30_to_60       3945 non-null   Float64            \n",
      " 19  change_0_60           3945 non-null   Float64            \n",
      "dtypes: Float64(12), category(3), datetime64[ns, UTC](4), string(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Plotter\n",
    "plotter = Plotter(figsize=(4, 3), save_fig=True)\n",
    "\n",
    "# Plot histograms\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='cvss',\n",
    "    title='Frequency of CVEs with varying CVSS scores',\n",
    "    xlabel='CVSS Score',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=50,\n",
    "    alpha=0.5,\n",
    "    ylim=(0, 2000)\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df=df[df['cvss_severity'] != 'UNKNOWN'],\n",
    "    column='cvss_severity',\n",
    "    title='Frequency of CVSS Severity Levels',\n",
    "    xlabel='CVSS Severity',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=5,\n",
    "    alpha=0.5,\n",
    "    ylim=(0, 5000)\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='exploit_count',\n",
    "    title='Distribution of Exploit Counts',\n",
    "    xlabel='Exploit Count',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=10,\n",
    "    alpha=0.5,\n",
    "    xlim=(0, 10),\n",
    "    ylim=(0, 5000),\n",
    "    transform='log',\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='days_to_poc_exploit',\n",
    "    title='Time to First Exploit Code Publishing',\n",
    "    xlabel='Days From Public Disclosure',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=100,\n",
    "    alpha=0.5,\n",
    "    xlim=(-500, 3000)\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='epss_0',\n",
    "    title='Histogram of EPSS Scores on Exploit Code Publish Date',\n",
    "    xlabel='EPSS Score',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=100,\n",
    "    alpha=0.5,\n",
    "    xlim=(0.001, 1.000),\n",
    "    ylim=(0, 200)\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='epss_0',\n",
    "    title='Histogram of EPSS Scores 30 Days After Exploit Code Publish Date',\n",
    "    xlabel='EPSS Score',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=100,\n",
    "    alpha=0.5,\n",
    "    xlim=(0.001, 1.000),\n",
    "    ylim=(0, 200)\n",
    ")\n",
    "plotter.plot_histogram(\n",
    "    df,\n",
    "    column='epss_0',\n",
    "    title='Histogram of EPSS Scores 60 Days After on Exploit Code Publish Date',\n",
    "    xlabel='EPSS Score',\n",
    "    ylabel='Number of CVEs',\n",
    "    bins=100,\n",
    "    alpha=0.5,\n",
    "    xlim=(0.001, 1.000),\n",
    "    ylim=(0, 200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Q-Q plots\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='cvss',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of CVSS Scores',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='CVSS Scores',\n",
    "    color='blue',\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    data=df[df['cvss_severity'] != 'UNKNOWN'],\n",
    "    column='cvss',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of CVSS Severity Levels',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='CVSS Severity Levels',\n",
    "    color='blue',\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='exploit_count',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of Exploit Count',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='Number of Exploits',\n",
    "    color='blue'\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='days_to_poc_exploit',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of the Interval Between CVE Disclosure and Exploit Code Publish Date',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='Days to Exploit Code Publishing',\n",
    "    color='blue',\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='epss_0',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of EPSS Scores on Exploit Code Publish Date',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='EPSS Scores',\n",
    "    color='blue',\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='epss_30',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of EPSS Scores 30 Days After on Exploit Code Publish Date',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='EPSS Scores',\n",
    "    color='blue',\n",
    ")\n",
    "plotter.plot_qq(\n",
    "    df,\n",
    "    column='epss_60',\n",
    "    dist='norm',\n",
    "    title='QQ Plot of EPSS Scores 60 Days After Exploit Code Publish Date',\n",
    "    xlabel='Theoretical Quantiles',\n",
    "    ylabel='EPSS Scores',\n",
    "    color='blue',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Normality Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cve_id                  730\n",
       "date_public             730\n",
       "origin                  730\n",
       "cvss                    710\n",
       "cvss_severity           730\n",
       "cvss_src                710\n",
       "exploit_count           730\n",
       "days_to_poc_exploit     730\n",
       "exploitation_date_0     730\n",
       "epss_0                  700\n",
       "percentile_0            628\n",
       "exploitation_date_30    730\n",
       "epss_30                 703\n",
       "percentile_30           702\n",
       "exploitation_date_60    730\n",
       "epss_60                 712\n",
       "percentile_60           707\n",
       "change_0_to_30          700\n",
       "change_30_to_60         700\n",
       "change_0_60             700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['origin'] == 'kev') | (df['origin'] == 'poc_kev')].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to test\n",
    "cvss = df['cvss']\n",
    "epss = df['epss']\n",
    "days_to_exploit = df['days_to_exploit']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
