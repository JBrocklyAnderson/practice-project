{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from the CVE Project\n",
    "This notebook is designed to scrape and process vulnerability data from over 260,000 JSON files, which are part of MITRE's CVE (Common Vulnerabilities and Exposures) project. The goal of this notebook is to extract key information that can be utilized in combination with other data from CISA, the NVD, and elsewhere in order to analyze the relationship between criticality, the speed of exploitation, and the importance of proper patching in the Internet-of-Things (IoT) space. Utilizing recursive searching, this notebook uses recursive searching techniques to efficiently navigate through the JSON file structure, collecting relevant data for further assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For traversing and reading folders and files\n",
    "import json # For reading and extracting data from CVE records\n",
    "import re # Handle regex patterns\n",
    "import xml.etree.ElementTree as ET # For reading and extracting data from CWE records\n",
    "import pandas as pd # For data cleaning and analysis\n",
    "import numpy as np # For advanced calculations\n",
    "import matplotlib.pyplot as plt # For data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "There are precisely $264,610$ records in the CVE list; each is represented by a single JSON file. These files contain all the information (though lots of it is incomplete) that will populate our primary dataframe. It was clear after creating the initial script that massive discrepencacies existed between the files' structures. This makes the use of recusive searching particularly beneficial, as it's far more flexible and easier to maintain that a program with explicitly-design conditionality statements covering as many cases as possible. If any more data is needed, this collection function can be easily adapted to fit future requirements. The data currently retrieved from this program populates a dataframe with the following variables: CVE IDs, CWE IDs (Common Weakness Enumeration), publication dates, vulnerability descriptions, four types of severity scores (CVSS 2.0, 3.0, 3.1, and 4.0), affected vendors, and impacted products."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def search(obj, key_to_find, parent_key=None, expected_type=None):\n",
    "    # If the object is not a dictionary or list, end search\n",
    "    if not isinstance(obj, (dict, list)):\n",
    "        return None\n",
    "\n",
    "    # If the current object is a dictionary\n",
    "    if isinstance(obj, dict):\n",
    "        # Check if current dictionary has the parent key\n",
    "        if parent_key and parent_key in obj:\n",
    "            parent_value = obj[parent_key]\n",
    "            result = search(parent_value, key_to_find, None, expected_type)\n",
    "            if result is not None:\n",
    "                return result\n",
    "\n",
    "        elif not parent_key and key_to_find in obj:\n",
    "            value = obj[key_to_find]\n",
    "            if expected_type is None or isinstance(value, expected_type):\n",
    "                return value\n",
    "\n",
    "        for value in obj.values():\n",
    "            result = search(value, key_to_find, parent_key, expected_type)\n",
    "            if result is not None:\n",
    "                return result\n",
    "\n",
    "    # If the current object is a list\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            result = search(item, key_to_find, parent_key, expected_type)\n",
    "            if result is not None:\n",
    "                return result\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            cve = json.load(file)\n",
    "\n",
    "            cve_id = search(cve, 'cveId')\n",
    "            cwe_id = search(cve, 'cweId', parent_key='problemTypes')\n",
    "            cve_state = search(cve, 'state',)\n",
    "            date_published = search(cve, 'datePublished')\n",
    "            date_public = search(cve, 'datePublic', parent_key='cna')\n",
    "            description = search(cve, 'value', parent_key='descriptions')\n",
    "            cvss_v4_0 = search(cve, 'baseScore', parent_key='cvssV4_0')\n",
    "            cvss_v3_1 = search(cve, 'baseScore', parent_key='cvssV3_1')\n",
    "            cvss_v3_0 = search(cve, 'baseScore', parent_key='cvssV3_0')\n",
    "            cvss_v2_0 = search(cve, 'baseScore', parent_key='cvssV2_0')\n",
    "            product = search(cve, 'product', parent_key='cna')\n",
    "            vendor = search(cve, 'vendor', parent_key='cna')\n",
    "            # attack_vector = search(cve, 'attackVector')\n",
    "            # attack_complexity = search(cve, 'attackComplexity')\n",
    "\n",
    "            return {\n",
    "                'cve_id': cve_id,\n",
    "                'cwe_id': cwe_id,\n",
    "                'cve_state': cve_state,\n",
    "                'date_published': date_published,\n",
    "                'date_public': date_public,\n",
    "                'description': description,\n",
    "                'cvss_v4_0': cvss_v4_0,\n",
    "                'cvss_v3_1': cvss_v3_1,\n",
    "                'cvss_v3_0': cvss_v3_0,\n",
    "                'cvss_v2_0': cvss_v2_0,\n",
    "                'vendor': vendor,\n",
    "                'product': product\n",
    "                # 'attack_vector': attack_vector,\n",
    "                # 'attack_complexity': attack_complexity\n",
    "            }\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f'Error reading {file_path}: {e}')\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected error reading {file_path}: {e}')\n",
    "    return None\n",
    "\n",
    "def process_files(base_dir):\n",
    "    data = []\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(base_dir))\n",
    "    file_count = 0\n",
    "    print(total_files)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.json'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                cve_data = extract_data(file_path)\n",
    "\n",
    "                if cve_data:\n",
    "                    data.append(cve_data)\n",
    "\n",
    "                file_count += 1\n",
    "                print(f'File {file_count} of {total_files}: {file_count / total_files * 100:.2f}%', end='\\r')\n",
    "\n",
    "    print('\\nAll files processed!')\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "base_dir = '../data/CVE_Project/cvelistV5/cves'\n",
    "df = process_files(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Data\n",
    "Parquet is a file type that streamlines the storage and retrieval of columnar data since it is capable of saving the type of data within the set. Even though CSV files do not have this capability, they are easily shared and viewable in common spreadsheet software. Because of this, I saved a copy with both file extensions. I chose to use the default option `None` for the method's `index` parameter, which saves the index of each record in a special kind of metadata range loop. This means it won't take up the kind of memory it would have if the index was actually saved into the dataframe as a separate attribute, but also provides a way to keep track of the records for the purposes of splitting them up between training, test, and validation sets for an machine-learning algorithm should our work come to that.\n",
    "\n",
    "<span style='font-weight:600;color:#ff9900;background-color:#525767;border-radius:3px;padding-inline:3px;padding-block:1px;'>Don't run this code cell unless you want to overwrite the saved files!</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Saving CVE list\n",
    "df.to_parquet(path='../data/CVE_Project/cvelistV5/cve_list_v2.parquet', index=None)\n",
    "df.to_csv('../data/CVE_Project/cvelistV5/cve_list_v2.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
